

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from torch.utils.data import DataLoader, TensorDataset
plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签
plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号

data = pd.read_excel(r"D:\\Documents\\Desktop\\建模比赛\\数据\\上海（合并）.xlsx")
# ========== 1. 参数设置 ==========
seq_length = 14
input_size = 14
hidden_size = 80
num_layers = 1
batch_size = 128
dropout = 0.3
learning_rate = 0.0005
epochs = 200
patience = 30

# ========== 2. 数据读取与处理 ==========
# 读取数据

data["Date"] = pd.to_datetime(data["Date"])

# 时间编码
data["Month_sin"] = np.sin(2 * np.pi * data["Date"].dt.month / 12)
data["Month_cos"] = np.cos(2 * np.pi * data["Date"].dt.month / 12)
data["Week_sin"] = np.sin(2 * np.pi * data["Date"].dt.dayofweek / 7)
data["Week_cos"] = np.cos(2 * np.pi * data["Date"].dt.dayofweek / 7)
# ========== 新增季度编码 ==========
data["Quarter_sin"] = np.sin(2 * np.pi * (data["Date"].dt.quarter - 1) / 4)
data["Quarter_cos"] = np.cos(2 * np.pi * (data["Date"].dt.quarter - 1) / 4)

# 添加滞后和移动平均特征
lag_days = 3
window_size = 5
for col in ["pm25_1", "平均气温", "湿度"]:
    for lag in range(1, lag_days+1):
        data[f"{col}_lag_{lag}"] = data[col].shift(lag)
data["pm25_1_MA5"] = data["pm25_1"].rolling(window=window_size).mean()

data = data.iloc[lag_days + window_size - 1:].reset_index(drop=True)
data["pm10"] = data["pm10"].interpolate(method="linear")
data["o3"] = data["o3"].interpolate(method="linear")
data["no2"] = data["no2"].interpolate(method="linear")
data["so2"] = data["so2"].interpolate(method="linear")
data["co"] = data["co"].interpolate(method="linear")
# 特征选择
data["Day"] = data["Date"].dt.day  # 直接输入“日”
data["National_Day"] = (data["Date"].dt.month == 10) & (data["Date"].dt.day == 1)
data["Labor_Day"] = (data["Date"].dt.month == 5) & (data["Date"].dt.day == 1)
data["IsHoliday"] = (data["National_Day"] | data["Labor_Day"]).astype(int)
data = data.drop(["National_Day", "Labor_Day"], axis=1)
features = ["能见度","pm10","no2","so2","co","风速m/s",
    "Month_sin", "Month_cos", "Week_sin", "Week_cos","Day","pm25_1_lag_1","pm25_1_MA5","GDP-SH_Index"
]
target = "pm25_1"

# 标准化
scaler = StandardScaler()
data_scaled = scaler.fit_transform(data[features + [target]])
data = pd.DataFrame(data_scaled, columns=features + [target])

# ========== 3. 构造时间序列数据 ==========
def create_sequences(data, seq_length):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:i+seq_length, :-1])
        y.append(data[i+seq_length, -1])
    return np.array(X), np.array(y)

X, y = create_sequences(data.values, seq_length)
train_size = int(len(X) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))
test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32))

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

# ========== 4. 定义 LSTM 模型 ==========
class LSTMPredictor(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, dropout):
        super().__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)
        self.fc = nn.Sequential(
            nn.Linear(hidden_size, hidden_size // 2),
            nn.ReLU(),
            nn.Linear(hidden_size // 2, 1)
        )

    def forward(self, x):
        lstm_out, _ = self.lstm(x)
        output = self.fc(lstm_out[:, -1, :]).squeeze()
        return output

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = LSTMPredictor(input_size, hidden_size, num_layers, dropout).to(device)

# ========== 5. 训练模型 ==========
criterion = nn.SmoothL1Loss()
optimizer = optim.AdamW(model.parameters(), lr=learning_rate)
scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)

def train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, epochs, patience):
    best_loss = float('inf')
    early_stop = 0
    for epoch in range(epochs):
        model.train()
        train_loss = 0
        for X_batch, y_batch in train_loader:
            X_batch, y_batch = X_batch.to(device), y_batch.to(device)
            optimizer.zero_grad()
            loss = criterion(model(X_batch), y_batch)
            loss.backward()
            optimizer.step()
            train_loss += loss.item()
        train_loss /= len(train_loader)

        # 计算 val loss
        model.eval()
        val_loss = 0
        with torch.no_grad():
            for X_val, y_val in test_loader:
                X_val, y_val = X_val.to(device), y_val.to(device)
                val_loss += criterion(model(X_val), y_val).item()
        val_loss /= len(test_loader)
        
        print(f"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}")

        # 早停
        if val_loss < best_loss:
            best_loss = val_loss
            torch.save(model.state_dict(), "lstm.pth")
            early_stop = 0
        else:
            early_stop += 1
            if early_stop >= patience:
                print("Early stopping!")
                break

train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, epochs, patience)

# ========== 6. 预测与评估 ==========
model.load_state_dict(torch.load("lstm.pth"))
model.eval()

y_pred = []
with torch.no_grad():
    for X_batch, _ in test_loader:
        y_pred.extend(model(X_batch.to(device)).cpu().numpy())

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# 逆标准化
y_test_real = scaler.inverse_transform(np.column_stack((X_test[:, -1, :], y_test)))[:, -1]
y_pred_real = scaler.inverse_transform(np.column_stack((X_test[:, -1, :], y_pred)))[:, -1]

# 计算评估指标
mae = mean_absolute_error(y_test_real, y_pred_real)
mse = mean_squared_error(y_test_real, y_pred_real)
r2 = r2_score(y_test_real, y_pred_real)

print(f"MAE (Mean Absolute Error): {mae:.2f}")
print(f"MSE (Mean Squared Error): {mse:.2f}")
print(f"R² Score: {r2:.4f}")

# 画图对比预测值和真实值
plt.figure(figsize=(12, 6))
plt.plot(y_test_real, label="真实值", alpha=0.7)
plt.plot(y_pred_real, label="预测值", alpha=0.7)
plt.title("PM2.5 预测结果对比")
plt.xlabel("时间步")
plt.ylabel("PM2.5 浓度")
plt.legend()
plt.show()

